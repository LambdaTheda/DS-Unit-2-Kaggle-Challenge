{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Wed Apr 15 4am Random Forest ass- PT5 DS_222.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LambdaTheda/DS-Unit-2-Kaggle-Challenge/blob/master/Wed_Apr_15_4am_Random_Forest_ass_PT5_DS_222.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDp4grBoUMIX",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 2, Module 2*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "# Random Forests\n",
        "\n",
        "## Assignment\n",
        "- [ ] Read [“Adopting a Hypothesis-Driven Workflow”](https://outline.com/5S5tsB), a blog post by a Lambda DS student about the Tanzania Waterpumps challenge.\n",
        "- [ ] Continue to participate in our Kaggle challenge.\n",
        "- [ ] Define a function to wrangle train, validate, and test sets in the same way. Clean outliers and engineer features.\n",
        "- [ ] Try Ordinal Encoding.\n",
        "- [ ] Try a Random Forest Classifier.\n",
        "- [ ] Submit your predictions to our Kaggle competition. (Go to our Kaggle InClass competition webpage. Use the blue **Submit Predictions** button to upload your CSV file. Or you can use the Kaggle API to submit your predictions.)\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "### Doing\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Do more exploratory data analysis, data cleaning, feature engineering, and feature selection.\n",
        "- [ ] Try other [categorical encodings](https://contrib.scikit-learn.org/categorical-encoding/).\n",
        "- [ ] Get and plot your feature importances.\n",
        "- [ ] Make visualizations and share on Slack.\n",
        "\n",
        "### Reading\n",
        "\n",
        "Top recommendations in _**bold italic:**_\n",
        "\n",
        "#### Decision Trees\n",
        "- A Visual Introduction to Machine Learning, [Part 1: A Decision Tree](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/),  and _**[Part 2: Bias and Variance](http://www.r2d3.us/visual-intro-to-machine-learning-part-2/)**_\n",
        "- [Decision Trees: Advantages & Disadvantages](https://christophm.github.io/interpretable-ml-book/tree.html#advantages-2)\n",
        "- [How a Russian mathematician constructed a decision tree — by hand — to solve a medical problem](http://fastml.com/how-a-russian-mathematician-constructed-a-decision-tree-by-hand-to-solve-a-medical-problem/)\n",
        "- [How decision trees work](https://brohrer.github.io/how_decision_trees_work.html)\n",
        "- [Let’s Write a Decision Tree Classifier from Scratch](https://www.youtube.com/watch?v=LDRbO9a6XPU)\n",
        "\n",
        "#### Random Forests\n",
        "- [_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/), Chapter 8: Tree-Based Methods\n",
        "- [Coloring with Random Forests](http://structuringtheunstructured.blogspot.com/2017/11/coloring-with-random-forests.html)\n",
        "- _**[Random Forests for Complete Beginners: The definitive guide to Random Forests and Decision Trees](https://victorzhou.com/blog/intro-to-random-forests/)**_\n",
        "\n",
        "#### Categorical encoding for trees\n",
        "- [Are categorical variables getting lost in your random forests?](https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/)\n",
        "- [Beyond One-Hot: An Exploration of Categorical Variables](http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/)\n",
        "- _**[Categorical Features and Encoding in Decision Trees](https://medium.com/data-design/visiting-categorical-features-and-encoding-in-decision-trees-53400fa65931)**_\n",
        "- _**[Coursera — How to Win a Data Science Competition: Learn from Top Kagglers — Concept of mean encoding](https://www.coursera.org/lecture/competitive-data-science/concept-of-mean-encoding-b5Gxv)**_\n",
        "- [Mean (likelihood) encodings: a comprehensive study](https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study)\n",
        "- [The Mechanics of Machine Learning, Chapter 6: Categorically Speaking](https://mlbook.explained.ai/catvars.html)\n",
        "\n",
        "#### Imposter Syndrome\n",
        "- [Effort Shock and Reward Shock (How The Karate Kid Ruined The Modern World)](http://www.tempobook.com/2014/07/09/effort-shock-and-reward-shock/)\n",
        "- [How to manage impostor syndrome in data science](https://towardsdatascience.com/how-to-manage-impostor-syndrome-in-data-science-ad814809f068)\n",
        "- [\"I am not a real data scientist\"](https://brohrer.github.io/imposter_syndrome.html)\n",
        "- _**[Imposter Syndrome in Data Science](https://caitlinhudon.com/2018/01/19/imposter-syndrome-in-data-science/)**_\n",
        "\n",
        "\n",
        "### More Categorical Encodings\n",
        "\n",
        "**1.** The article **[Categorical Features and Encoding in Decision Trees](https://medium.com/data-design/visiting-categorical-features-and-encoding-in-decision-trees-53400fa65931)** mentions 4 encodings:\n",
        "\n",
        "- **\"Categorical Encoding\":** This means using the raw categorical values as-is, not encoded. Scikit-learn doesn't support this, but some tree algorithm implementations do. For example, [Catboost](https://catboost.ai/), or R's [rpart](https://cran.r-project.org/web/packages/rpart/index.html) package.\n",
        "- **Numeric Encoding:** Synonymous with Label Encoding, or \"Ordinal\" Encoding with random order. We can use [category_encoders.OrdinalEncoder](https://contrib.scikit-learn.org/categorical-encoding/ordinal.html).\n",
        "- **One-Hot Encoding:** We can use [category_encoders.OneHotEncoder](http://contrib.scikit-learn.org/categorical-encoding/onehot.html).\n",
        "- **Binary Encoding:** We can use [category_encoders.BinaryEncoder](http://contrib.scikit-learn.org/categorical-encoding/binary.html).\n",
        "\n",
        "\n",
        "**2.** The short video \n",
        "**[Coursera — How to Win a Data Science Competition: Learn from Top Kagglers — Concept of mean encoding](https://www.coursera.org/lecture/competitive-data-science/concept-of-mean-encoding-b5Gxv)** introduces an interesting idea: use both X _and_ y to encode categoricals.\n",
        "\n",
        "Category Encoders has multiple implementations of this general concept:\n",
        "\n",
        "- [CatBoost Encoder](http://contrib.scikit-learn.org/categorical-encoding/catboost.html)\n",
        "- [James-Stein Encoder](http://contrib.scikit-learn.org/categorical-encoding/jamesstein.html)\n",
        "- [Leave One Out](http://contrib.scikit-learn.org/categorical-encoding/leaveoneout.html)\n",
        "- [M-estimate](http://contrib.scikit-learn.org/categorical-encoding/mestimate.html)\n",
        "- [Target Encoder](http://contrib.scikit-learn.org/categorical-encoding/targetencoder.html)\n",
        "- [Weight of Evidence](http://contrib.scikit-learn.org/categorical-encoding/woe.html)\n",
        "\n",
        "Category Encoder's mean encoding implementations work for regression problems or binary classification problems. \n",
        "\n",
        "For multi-class classification problems, you will need to temporarily reformulate it as binary classification. For example:\n",
        "\n",
        "```python\n",
        "encoder = ce.TargetEncoder(min_samples_leaf=..., smoothing=...) # Both parameters > 1 to avoid overfitting\n",
        "X_train_encoded = encoder.fit_transform(X_train, y_train=='functional')\n",
        "X_val_encoded = encoder.transform(X_train, y_val=='functional')\n",
        "```\n",
        "\n",
        "For this reason, mean encoding won't work well within pipelines for multi-class classification problems.\n",
        "\n",
        "**3.** The **[dirty_cat](https://dirty-cat.github.io/stable/)** library has a Target Encoder implementation that works with multi-class classification.\n",
        "\n",
        "```python\n",
        " dirty_cat.TargetEncoder(clf_type='multiclass-clf')\n",
        "```\n",
        "It also implements an interesting idea called [\"Similarity Encoder\" for dirty categories](https://www.slideshare.net/GaelVaroquaux/machine-learning-on-non-curated-data-154905090).\n",
        "\n",
        "However, it seems like dirty_cat doesn't handle missing values or unknown categories as well as category_encoders does. And you may need to use it with one column at a time, instead of with your whole dataframe.\n",
        "\n",
        "**4. [Embeddings](https://www.kaggle.com/learn/embeddings)** can work well with sparse / high cardinality categoricals.\n",
        "\n",
        "_**I hope it’s not too frustrating or confusing that there’s not one “canonical” way to encode categoricals. It’s an active area of research and experimentation! Maybe you can make your own contributions!**_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ls9RKa2UMI6",
        "colab_type": "text"
      },
      "source": [
        "### Setup\n",
        "\n",
        "You can work locally (follow the [local setup instructions](https://lambdaschool.github.io/ds/unit2/local/)) or on Colab (run the code cell below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "    !pip install pandas-profiling==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QJBD4ruICm1m",
        "outputId": "cea0f896-2c68-48f0-b598-b51d6d1efbb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
        "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n",
        "test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
        "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')\n",
        "\n",
        "train.shape, test.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((59400, 41), (14358, 40))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrgP3-A3O-dI",
        "colab_type": "text"
      },
      "source": [
        "## Pre-processing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvfCtziwPDTN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6cff8256-86f0-4696-ef01-23aa4733a0a8"
      },
      "source": [
        "# Split Val dataset from Train data\n",
        "train, val = train_test_split(train, train_size = 0.80, test_size = 0.20,\n",
        "                              stratify = train['status_group'], random_state = 42)\n",
        "\n",
        "print('Train shape:', train.shape, ', Val shape:', val.shape, ', Test shape:', test.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape: (9964, 41) , Val shape: (2492, 41) , Test shape: (14358, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP3U210ZQA8G",
        "colab_type": "text"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2aZTQeOQGJG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "f6af3318-b3ea-4e13-8a56-bdf62f0e837f"
      },
      "source": [
        "# Examine train's numeric variables\n",
        "train.describe()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>amount_tsh</th>\n",
              "      <th>gps_height</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>num_private</th>\n",
              "      <th>region_code</th>\n",
              "      <th>district_code</th>\n",
              "      <th>population</th>\n",
              "      <th>construction_year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>30412.000000</td>\n",
              "      <td>30412.000000</td>\n",
              "      <td>30412.000000</td>\n",
              "      <td>30412.000000</td>\n",
              "      <td>3.041200e+04</td>\n",
              "      <td>30412.000000</td>\n",
              "      <td>30412.000000</td>\n",
              "      <td>30412.000000</td>\n",
              "      <td>30412.000000</td>\n",
              "      <td>30412.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>37113.828818</td>\n",
              "      <td>330.019045</td>\n",
              "      <td>670.627022</td>\n",
              "      <td>34.082925</td>\n",
              "      <td>-5.691943e+00</td>\n",
              "      <td>0.455675</td>\n",
              "      <td>15.236321</td>\n",
              "      <td>5.638301</td>\n",
              "      <td>179.235729</td>\n",
              "      <td>1305.952979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>21367.048328</td>\n",
              "      <td>2990.719604</td>\n",
              "      <td>693.202431</td>\n",
              "      <td>6.548460</td>\n",
              "      <td>2.934514e+00</td>\n",
              "      <td>12.974291</td>\n",
              "      <td>17.508416</td>\n",
              "      <td>9.663472</td>\n",
              "      <td>463.655022</td>\n",
              "      <td>949.997688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-63.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.156858e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>18656.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.083734</td>\n",
              "      <td>-8.510397e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>37114.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>376.000000</td>\n",
              "      <td>34.909382</td>\n",
              "      <td>-5.002823e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>1986.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>55469.500000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>1319.000000</td>\n",
              "      <td>37.168978</td>\n",
              "      <td>-3.326633e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>213.000000</td>\n",
              "      <td>2004.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>74247.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>2770.000000</td>\n",
              "      <td>40.344301</td>\n",
              "      <td>-2.000000e-08</td>\n",
              "      <td>1776.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>15300.000000</td>\n",
              "      <td>2013.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id     amount_tsh  ...    population  construction_year\n",
              "count  30412.000000   30412.000000  ...  30412.000000       30412.000000\n",
              "mean   37113.828818     330.019045  ...    179.235729        1305.952979\n",
              "std    21367.048328    2990.719604  ...    463.655022         949.997688\n",
              "min        0.000000       0.000000  ...      0.000000           0.000000\n",
              "25%    18656.750000       0.000000  ...      0.000000           0.000000\n",
              "50%    37114.500000       0.000000  ...     30.000000        1986.000000\n",
              "75%    55469.500000      25.000000  ...    213.000000        2004.000000\n",
              "max    74247.000000  250000.000000  ...  15300.000000        2013.000000\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTHdt1CkQQkb",
        "colab_type": "text"
      },
      "source": [
        "# Examine train's non-numeric variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-PAnsy-QSw_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        },
        "outputId": "b29cfd31-1c69-4bf8-ae2b-3ee112420a4a"
      },
      "source": [
        "train.describe(exclude = 'number').T # Transpose/\"switch\" Row and Column orientaiton for legibility"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>date_recorded</th>\n",
              "      <td>30412</td>\n",
              "      <td>334</td>\n",
              "      <td>2011-03-17</td>\n",
              "      <td>309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>funder</th>\n",
              "      <td>28581</td>\n",
              "      <td>1407</td>\n",
              "      <td>Government Of Tanzania</td>\n",
              "      <td>4698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>installer</th>\n",
              "      <td>28571</td>\n",
              "      <td>1555</td>\n",
              "      <td>DWE</td>\n",
              "      <td>9008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wpt_name</th>\n",
              "      <td>30412</td>\n",
              "      <td>20659</td>\n",
              "      <td>none</td>\n",
              "      <td>1857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>basin</th>\n",
              "      <td>30412</td>\n",
              "      <td>9</td>\n",
              "      <td>Lake Victoria</td>\n",
              "      <td>5214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>subvillage</th>\n",
              "      <td>30227</td>\n",
              "      <td>13467</td>\n",
              "      <td>Majengo</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>region</th>\n",
              "      <td>30412</td>\n",
              "      <td>21</td>\n",
              "      <td>Iringa</td>\n",
              "      <td>2755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lga</th>\n",
              "      <td>30412</td>\n",
              "      <td>124</td>\n",
              "      <td>Njombe</td>\n",
              "      <td>1315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ward</th>\n",
              "      <td>30412</td>\n",
              "      <td>2057</td>\n",
              "      <td>Igosi</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>public_meeting</th>\n",
              "      <td>28746</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>26136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recorded_by</th>\n",
              "      <td>30412</td>\n",
              "      <td>1</td>\n",
              "      <td>GeoData Consultants Ltd</td>\n",
              "      <td>30412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>scheme_management</th>\n",
              "      <td>28433</td>\n",
              "      <td>12</td>\n",
              "      <td>VWC</td>\n",
              "      <td>18901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>scheme_name</th>\n",
              "      <td>15997</td>\n",
              "      <td>2257</td>\n",
              "      <td>K</td>\n",
              "      <td>350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>permit</th>\n",
              "      <td>28838</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>19846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extraction_type</th>\n",
              "      <td>30412</td>\n",
              "      <td>18</td>\n",
              "      <td>gravity</td>\n",
              "      <td>13713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extraction_type_group</th>\n",
              "      <td>30412</td>\n",
              "      <td>13</td>\n",
              "      <td>gravity</td>\n",
              "      <td>13713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extraction_type_class</th>\n",
              "      <td>30412</td>\n",
              "      <td>7</td>\n",
              "      <td>gravity</td>\n",
              "      <td>13713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>management</th>\n",
              "      <td>30412</td>\n",
              "      <td>12</td>\n",
              "      <td>vwc</td>\n",
              "      <td>20790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>management_group</th>\n",
              "      <td>30412</td>\n",
              "      <td>5</td>\n",
              "      <td>user-group</td>\n",
              "      <td>26913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>payment</th>\n",
              "      <td>30412</td>\n",
              "      <td>7</td>\n",
              "      <td>never pay</td>\n",
              "      <td>12957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>payment_type</th>\n",
              "      <td>30412</td>\n",
              "      <td>7</td>\n",
              "      <td>never pay</td>\n",
              "      <td>12957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>water_quality</th>\n",
              "      <td>30412</td>\n",
              "      <td>8</td>\n",
              "      <td>soft</td>\n",
              "      <td>26034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>quality_group</th>\n",
              "      <td>30412</td>\n",
              "      <td>6</td>\n",
              "      <td>good</td>\n",
              "      <td>26034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>quantity</th>\n",
              "      <td>30412</td>\n",
              "      <td>5</td>\n",
              "      <td>enough</td>\n",
              "      <td>17010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>quantity_group</th>\n",
              "      <td>30412</td>\n",
              "      <td>5</td>\n",
              "      <td>enough</td>\n",
              "      <td>17010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>source</th>\n",
              "      <td>30412</td>\n",
              "      <td>10</td>\n",
              "      <td>shallow well</td>\n",
              "      <td>8703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>source_type</th>\n",
              "      <td>30412</td>\n",
              "      <td>7</td>\n",
              "      <td>shallow well</td>\n",
              "      <td>8703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>source_class</th>\n",
              "      <td>30412</td>\n",
              "      <td>3</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>23406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>waterpoint_type</th>\n",
              "      <td>30412</td>\n",
              "      <td>7</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>14561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>waterpoint_type_group</th>\n",
              "      <td>30412</td>\n",
              "      <td>6</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>17661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>status_group</th>\n",
              "      <td>30412</td>\n",
              "      <td>3</td>\n",
              "      <td>functional</td>\n",
              "      <td>16517</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       count unique                      top   freq\n",
              "date_recorded          30412    334               2011-03-17    309\n",
              "funder                 28581   1407   Government Of Tanzania   4698\n",
              "installer              28571   1555                      DWE   9008\n",
              "wpt_name               30412  20659                     none   1857\n",
              "basin                  30412      9            Lake Victoria   5214\n",
              "subvillage             30227  13467                  Majengo    282\n",
              "region                 30412     21                   Iringa   2755\n",
              "lga                    30412    124                   Njombe   1315\n",
              "ward                   30412   2057                    Igosi    163\n",
              "public_meeting         28746      2                     True  26136\n",
              "recorded_by            30412      1  GeoData Consultants Ltd  30412\n",
              "scheme_management      28433     12                      VWC  18901\n",
              "scheme_name            15997   2257                        K    350\n",
              "permit                 28838      2                     True  19846\n",
              "extraction_type        30412     18                  gravity  13713\n",
              "extraction_type_group  30412     13                  gravity  13713\n",
              "extraction_type_class  30412      7                  gravity  13713\n",
              "management             30412     12                      vwc  20790\n",
              "management_group       30412      5               user-group  26913\n",
              "payment                30412      7                never pay  12957\n",
              "payment_type           30412      7                never pay  12957\n",
              "water_quality          30412      8                     soft  26034\n",
              "quality_group          30412      6                     good  26034\n",
              "quantity               30412      5                   enough  17010\n",
              "quantity_group         30412      5                   enough  17010\n",
              "source                 30412     10             shallow well   8703\n",
              "source_type            30412      7             shallow well   8703\n",
              "source_class           30412      3              groundwater  23406\n",
              "waterpoint_type        30412      7       communal standpipe  14561\n",
              "waterpoint_type_group  30412      6       communal standpipe  17661\n",
              "status_group           30412      3               functional  16517"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLGUQoV0WoB7",
        "colab_type": "text"
      },
      "source": [
        "### Define a function to wrangle train, validate, and test sets in the same way. Clean outliers..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Spzp7edUMJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def wrangle(X):\n",
        "  # Prevent SettingWithCopyWarning\n",
        "  X = X.copy()\n",
        "\n",
        "  '''\n",
        "  CLEAN OUTLIERS: \n",
        "  About 3% of the time, latitude has small values near zero,\n",
        "  outside Tanzania, so we'll treat these values like zeroes\n",
        "  '''\n",
        "  X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
        "\n",
        "  # When columns have zeros and shouldn't, they are like null values.  # So we will replace the zeros with nulls, and impute missing values later.\n",
        "  cols_with_zeros = ['longitude','latutude']\n",
        "  for col in cols_with_zeroes:\n",
        "    X[col] = X[col].replace(0, np.nan)\n",
        "   \n",
        "   # Drop duplicate columns\n",
        "    duplicates = ['quantity_group', 'payment_type']\n",
        "    X = X.drop(columns = duplicates) # (quantity & quantity_group), (payment & payment_type) are duplicates, so drop one from each set\n",
        "\n",
        "   # Drop columns that always or never varies\n",
        "    unusable_variance = ['recorded_by', 'id']\n",
        "    X = X.drop(columns = unusable_variance) \n",
        "\n",
        "   # Convert date_recorded to dateime\n",
        "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format = True)\n",
        "   \n",
        "   # Extract components from date_recorded, then drop original column\n",
        "    X['year_recorded'] = X['date_recorded'].dt.year\n",
        "    X['month_recorded'] = X['month_recorded'].dt.month\n",
        "    X['day_recorded'] = X['day_recorded'].dt.day\n",
        "\n",
        "    X = X.drop(columns = 'date_recorded')\n",
        "                          \n",
        "   # Engineer feature: age of waterpump = date_recorded - construction_year \n",
        "    X['waterpump_age'] = X['year_recorded'] - X['construction_year']\n",
        "    X['years_MISSING'] = X['waterpump_age'].isnull()\n",
        "   \n",
        "   # return the wrangled dataframe\n",
        "\n",
        "  return X\n",
        "\n",
        "  train = wrangle(train)\n",
        "  val = wrangle(val)\n",
        "  test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKc3zxrKbyK6",
        "colab_type": "text"
      },
      "source": [
        "### Profile Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VygsUSRb568",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check Pandas Profiling version\n",
        "\n",
        "import pandas_profiling\n",
        "pandas_profiling.__version__ #AttributeError: module 'pandas_profiling' has no attribute '__version__'\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ypwn-g0EcceF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# New code for Pandas Profiling version 2.4\n",
        "from pandas_profiling import ProfileReport\n",
        "\n",
        "profile = ProfileReport(train, minimal = True).to_notebook_iframe()\n",
        "profile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64uJue-NMueM",
        "colab_type": "text"
      },
      "source": [
        "### Ordinal Encoding-\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwwBntP2TkoJ",
        "colab_type": "text"
      },
      "source": [
        "involves mapping each unique label to an integer value. As such, it is sometimes referred to simply as an integer encoding  ~From: https://machinelearningmastery.com/how-to-prepare-categorical-data-for-deep-learning-in-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dGjanfiAAxj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85e0e478-3191-40b3-d658-aab7631d8068"
      },
      "source": [
        "#Arrange data into X features matrix and y target vector\n",
        "\n",
        "# y target vector is 'status_group' column\n",
        "target = 'status_group'\n",
        "\n",
        "# Train dataset\n",
        "X_train = train.drop(columns = target)\n",
        "y_train = train[target]\n",
        "\n",
        "# Validation dataset\n",
        "X_val = val.drop(columns = target)\n",
        "y_val = val[target]\n",
        "\n",
        "# Test dataset\n",
        "X_test = test\n",
        "\n",
        "print('Train shape:', X_train.shape, ', Val shape:', X_val.shape)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape: (30412, 40) , Val shape: (7604, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-iwjGaoUt78",
        "colab_type": "text"
      },
      "source": [
        "### Baseline Class Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoqhqnlJU30H",
        "colab_type": "text"
      },
      "source": [
        "functional class is mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLaOSzPeUd5r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "e7eae61d-223e-492a-c810-b55511d834ba"
      },
      "source": [
        "train['status_group'].value_counts(normalize = True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "functional                 0.543155\n",
              "non functional             0.384183\n",
              "functional needs repair    0.072662\n",
              "Name: status_group, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5rGHsb1VFOx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "450bf545-c828-4930-f69f-c69221adaae9"
      },
      "source": [
        "#Ordinal Encoding & Random Forest Classifier\n",
        "%time   #captures and prints runtime of cell computations; UsageError: Can't use statement directly after '%%time'!\n",
        "\n",
        "import category_encoders as ce\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    SimpleImputer(strategy = 'mean'),\n",
        "    RandomForestClassifier(random_state = 42, n_jobs = -1)\n",
        ")\n",
        "\n",
        "# Fit on Train & Score on Val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy:', pipeline.score(X_val, y_val)) "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.91 µs\n",
            "Validation Accuracy: 0.7994476591267754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CD2GszleH8D",
        "colab_type": "text"
      },
      "source": [
        "### Predict on Test set and Submit to Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP_k1_xpeQRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict on Test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Submit to Kaggle: \n",
        "'''\n",
        "1) Make a dataframe with 2 columns: id and status_group\n",
        "2) [they will be written] to a csv file, without the index\n",
        "'''\n",
        "submission = sample_submission.copy()\n",
        "submission['status_group'] = y_pred\n",
        "submission.to_csv('submission_forest_1.csv', index = False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}